---
title: HTML
description: "本模块主要包含HTML、网络和浏览器三大块知识，因为习惯三件套的说法，所以把后两者都归类到HTML中，实际上按内容来划分的话，网络>浏览器>HTML。"
---

## HTML

+++danger Doctype作用? 标准模式与兼容模式如何区分？
<!DOCTYPE> 声明位于文档中的最前面，处于html标签之前。告知浏览器以何种模式来渲染文档。
标准模式的排版和 JS 运作模式是 以该浏览器支持的最高标准运行。在兼容模式中，页面以宽松的向后兼容的方式显示。模拟老式浏览器的行为以防止站点无法工作。DOCTYPE不存在或格式不正确会导致文档以兼容模式呈现。
+++

+++danger 语义化标签

1. 利于SEO
2. 提高代码可读性

+++

+++danger  说一下 HTML5 drag api
darg：事件主体是被拖放元素，在正在拖放被拖放元素时触发。
dragstart：事件主体是被拖放元素，在开始拖放被拖放元素时触发，。
dragend：事件主体是被拖放元素，在整个拖放操作结束时触发
dragenter：事件主体是目标元素，在被拖放元素进入某元素时触发。
dragover：事件主体是目标元素，在被拖放在某元素内移动时触发。
dragleave：事件主体是目标元素，在被拖放元素移出目标元素是触发。
drop：事件主体是目标元素，在目标元素完全接受被拖放元素时触发。
+++

+++danger attribute和property区别
前者是HTML文档属性，后者是JS 获取DOM属性
+++

+++danger src和href的区别
src 是 source 的缩写，指向外部资源的位置，指向的内容将会嵌入到文档中当前标签所在位置；在请求 src 资源时会将其指向的资源下载并应用到文档内，例如 js 脚本，img 图片和 frame 等元素。当浏览器解析到该元素时，会暂停其他资源的下载和处理，直到将该资源加载、编译、执行完毕，图片和框架等元素也如此，类似于将所指向资源嵌入当前标签内。这也是为什么将js 脚本放在底部而不是头部。src用于img、input、style、script、iframe;
href 是 Hypertext Reference 的缩写，指向网络资源所在位置，建立和当前元素（锚点）或当前文档（链接）之间的链接，如果在文档中添加。那么浏览器会识别该文档为 css 文件，就会并行下载资源并且不会停止对当前文档的处理。 这也是为什么建议使用 link 方式来加载 css，而不是使用@import 方式。href用于link a 标签
+++

+++danger iframe 有那些优点和缺点？
优点：

- 用来加载速度较慢的内容（如广告）
- 可以使脚本可以并行下载
- 可以实现跨子域通信

缺点：

- iframe 会阻塞主页面的 onload 事件
- 无法被一些搜索引擎索识别
- 会产生很多页面，不容易管理

+++

## 网络

+++warning 七层模型和相关协议

![OSI7](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/c1e8e168d9f249788c74c5b50e0528e2~tplv-k3u1fbpfcp-zoom-in-crop-mark:3024:0:0:0.awebp)
应用层：允许访问OSI环境的手段（应用协议数据单元APDU）
表示层：对数据进行翻译、加密和压缩（表示协议数据单元PPDU）
会话层：建立、管理和终止会话（会话协议数据单元SPDU）
传输层：提供端到端的可靠报文传递和错误恢复（段Segment）
网络层：负责数据包从源到宿的传递和网际互连（包PackeT）
数据链路层：将比特组装成帧和点到点的传递（帧Frame）
物理层：通过媒介传输比特,确定机械及电气规范（比特Bit）

ICMP协议： 因特网控制报文协议。它是TCP/IP协议族的一个子协议，用于在IP主机、路由器之间传递控制消息。
TFTP协议： 是TCP/IP协议族中的一个用来在客户机与服务器之间进行简单文件传输的协议，提供不复杂、开销不大的文件传输服务。
HTTP协议： 超文本传输协议，是一个属于应用层的面向对象的协议，由于其简捷、快速的方式，适用于分布式超媒体信息系统。
DHCP协议： 动态主机配置协议，是一种让系统得以连接到网络上，并获取所需要的配置参数手段。
+++

+++warning TCP/IP五层协议
![TCP/IP5](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/48cd77d608714c298366f4dac77f33fb~tplv-k3u1fbpfcp-zoom-in-crop-mark:3024:0:0:0.awebp)

应用层 (application layer)：直接为应用进程提供服务。应用层协议定义的是应用进程间通讯和交互的规则，不同的应用有着不同的应用层协议，如 HTTP协议（万维网服务）、FTP协议（文件传输）、SMTP协议（电子邮件）、DNS（域名查询）等。
传输层 (transport layer)：有时也译为运输层，它负责为两台主机中的进程提供通信服务。该层主要有以下两种协议：
1、传输控制协议 (Transmission Control Protocol，TCP)：提供面向连接的、可靠的数据传输服务，数据传输的基本单位是报文段（segment）；
2、用户数据报协议 (User Datagram Protocol，UDP)：提供无连接的、尽最大努力的数据传输服务，但不保证数据传输的可靠性，数据传输的基本单位是用户数据报。
网络层 (internet layer)：有时也译为网际层，它负责为两台主机提供通信服务，并通过选择合适的路由将数据传递到目标主机。
数据链路层 (data link layer)：负责将网络层交下来的 IP 数据报封装成帧，并在链路的两个相邻节点间传送帧，每一帧都包含数据和必要的控制信息（如同步信息、地址信息、差错控制等）。
物理层 (physical Layer)：确保数据可以在各种物理媒介上进行传输，为数据的传输提供可靠的环境。

![TCP](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/8a89b9ddb9d541a880fee0dccd1c03e9~tplv-k3u1fbpfcp-zoom-in-crop-mark:3024:0:0:0.awebp)

![IP](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/2db9226a6cdb4ee48daecd9bc4181b64~tplv-k3u1fbpfcp-zoom-in-crop-mark:3024:0:0:0.awebp)
+++

+++warning URL组成
| 属性     | 含义         | 示例           |
| -------- | ------------ | -------------- |
| protocal | 协议         | http:          |
| hostname | 主机名       | 127.0.0.1      |
| port     | 端口号       | 8001           |
| host     | 主机         | 127.0.0.1:8001 |
| catalog  | 目录         | /xxx/xxx/      |
| pathname | 访问页面     | index.html     |
| hash     | 哈希值（锚） | #/aaa/bbb      |
| search   | 搜索内容     | ?a=100&b=20    |
+++

### HTTP

+++warning  HTTP协议的优点和缺点
HTTP 是超文本传输协议，它定义了客户端和服务器之间交换报文的格式和方式，默认使用 80 端口。它使用 TCP 作为传输层协议，保证了数据传输的可靠性。

HTTP协议具有以下优点：

1. 支持客户端/服务器模式
2. 简单快速：客户向服务器请求服务时，只需传送请求方法和路径。由于 HTTP 协议简单，使得 HTTP 服务器的程序规模小，因而通信速度很快。
3. 无连接：无连接就是限制每次连接只处理一个请求。服务器处理完客户的请求，并收到客户的应答后，即断开连接，采用这种方式可以节省传输时间。
4. 无状态：HTTP 协议是无状态协议，这里的状态是指通信过程的上下文信息。缺少状态意味着如果后续处理需要前面的信息，则它必须重传，这样可能会导致每次连接传送的数据量增大。另一方面，在服务器不需要先前信息时它的应答就比较快。
5. 灵活：HTTP 允许传输任意类型的数据对象。正在传输的类型由 Content-Type 加以标记。

HTTP协议具有以下缺点：

1. 无状态：HTTP 是一个无状态的协议，HTTP 服务器不会保存关于客户的任何信息。
2. 明文传输：协议中的报文使用的是文本形式，这就直接暴露给外界，不安全。
3. 不安全
（1）通信使用明文（不加密），内容可能会被窃听；
（2）不验证通信方的身份，因此有可能遭遇伪装；
（3）无法证明报文的完整性，所以有可能已遭篡改；

+++

+++warning 谈谈网络性能优化

1. 避免请求：采用强缓存和协商缓存，DNS缓存，CDN负载均衡
2. 减少请求：1.资源的懒加载 2.合并请求，如将静态资源合并成一个大文件 3.代理重定向
3. 压缩：1.图片视频等资源进行有损压缩 2.代码文本类进行无损压缩（Gzip）

+++

+++warning HTTP请求报文组成

1. 请求⾏：请求⽅法字段、URL字段、HTTP协议版本字段。它们⽤空格分隔。例如，GET /index.html HTTP/1.1。
2. 请求头部:请求头部由关键字/值对组成，每⾏⼀对，关键字和值⽤英⽂冒号“:”分隔  
3. 空行：回车符 + 换行符
4. 请求体: post put等请求携带的数据

![请求报文](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/4fb5bb2cb1664850b52e32d57af74f2f~tplv-k3u1fbpfcp-zoom-in-crop-mark:3024:0:0:0.awebp)

![请求报文](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/eacc55d7152149e99730346f1edfc9ab~tplv-k3u1fbpfcp-zoom-in-crop-mark:3024:0:0:0.awebp)
+++

+++warning HTTP响应报文组成
响应报文由四部分组成（响应行 + 响应头 + 空行 + 响应体）

响应行：HTTP 版本 + 空格 + 状态码 + 空格 + 状态码描述 + 回车符（CR） + 换行符（LF）
响应头：字段名 + 冒号 + 值 + 回车符 + 换行符
空行：回车符 + 换行符
响应体：由用户自定义添加，如 post 的 body 等

![响应报文](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/1b0183eb91ce451aa17bd515d047062d~tplv-k3u1fbpfcp-zoom-in-crop-mark:3024:0:0:0.awebp)
+++

+++warning get和post请求的区别

- 应用场景：GET 请求是一个幂等安全的请求，一般 Get 请求用于对服务器资源不会产生影响的场景，比如说请求一个网页的资源。而 Post 是一个不幂等不安全的请求，一般用于对服务器资源会产生影响的情景，比如注册用户这一类的操作。
- 是否缓存：因为两者应用场景不同，浏览器一般会对 Get 请求缓存，但很少对 Post 请求缓存。
- 发送的报文格式：Get 请求的报文中实体部分为空，Post 请求的报文中实体部分一般为向服务器发送的数据。
- 安全性：Get 请求可以将请求的参数放入 url 中向服务器发送，这样的做法相对于 Post 请求来说是不太安全的，因为请求的 url 会被保留在历史记录中。
- 请求长度：浏览器由于对 url 长度的限制，所以会影响 get 请求发送数据时的长度。这个限制是浏览器规定的，并不是 RFC 规定的。
- 参数类型：post 的参数传递支持更多的数据类型。

+++

+++warning 请求头字段、响应头字段有哪些，作用属性？
东西略多，可参考相应文章或者MDN
+++

+++warning OPTIONS请求方法及使用场景
OPTIONS方法是用于请求获得由Request-URI标识的资源在请求/响应的通信过程中可以使用的功能选项。通过这个方法，客户端可以在采取具体资源请求之前，决定对该资源采取何种必要措施，或者了解服务器的性能。该请求方法的响应不能缓存。

OPTIONS请求方法的主要用途有两个：

- 获取服务器支持的所有HTTP请求方法；
- 用来检查访问权限。例如：在进行 CORS 跨域资源共享时，对于复杂请求，就是使用 OPTIONS 方法发送嗅探请求，以判断是否有对指定资源的访问权限。

+++

#### HTTP各个版本

+++warning 简述HTTP各个版本改进
`HTTP2.0`

1. 二进制格式：HTTP2.0 基本单位为二进制，以往是采用文本形式，健壮性不是很好，现在采用二进制格式，更方便更健壮
2. 多路复用：把多个请求当做多个流，请求响应数据分成多个帧（帧可以标记资源让服务端识别），不同流中的帧交错发送，解决了 TCP 连接数量多、慢和队头阻塞的问题，所以对于同一个域名只用创建一个连接就可以了
3. 压缩消息头：客户端和服务端共同维护一个字典，重复发送同样请求头时只需要发送索引即可
4. HTTP2.0 服务端推送，浏览器发送请求后，服务端会主动发送与这个请求相关的资源，之后浏览器就不用再次发送后续的请求了

`HTTP1.1`

1. 长连接，可以在一个 TCP 连接上发送多个请求和响应，减少多次握手挥手消耗，但存在队头阻塞问题
2. 缓存处理新增 E-Tag、If-None-Match 之类的缓存来来控制缓存
3. 资源请求方面，在 http1.0 中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能，http1.1 则在请求头引入了 range 头域，它允许只请求资源的某个部分，即返回码是 206（Partial Content），这样就方便了开发者自由的选择以便于充分利用带宽和连接。
4. http1.1 中新增了 host 字段，用来指定服务器的域名。http1.0 中认为每台服务器都绑定一个唯一的 IP 地址，因此，请求消息中的 URL 并没有传递主机名（hostname）。但随着虚拟主机技术的发展，在一台物理服务器上可以存在多个虚拟主机，并且它们共享一个IP地址。因此有了 host 字段，这样就可以将请求发往到同一台服务器上的不同网站。
5. 多了 PUT、HEAD、OPTIONS等请求方法

+++

+++warning 谈谈HTTP2中的多路复用，为什么1.1中不能使用
在 HTTP1.1中即使开启了 Keep-Alive，解决了多次连接的问题，但是依然有两个效率上的问题：
一是服务端必须顺序响应文件，容易造成队头阻塞，二是连接数过多导致的性能问题。
HTTP2 的多路复用就是为了解决上述的两个性能问题。
在 HTTP/2 中，有两个非常重要的概念，分别是帧（frame）和流（stream）。帧代表着最小的数据单位，每个帧会标识出该帧属于哪个流，流也就是多个帧组成的数据流。
多路复用，就是在一个 TCP 连接中可以存在多条流。换句话说，也就是可以发送多个请求，对端可以通过帧中的标识知道属于哪个请求。通过这个技术，可以避免 HTTP 旧版本中的队头阻塞问题，极大的提高传输性能。
HTTP/1.1 不是二进制传输，而是通过文本进行传输。由于没有流的概念，在使用并行传输（多路复用）传递数据时，接收端在接收到响应后，并不能区分多个响应分别对应的请求，所以无法将多个响应的结果重新进行组装，也就实现不了多路复用。
+++

+++warning 页面有多张图片，HTTP是怎样的加载表现？

- 在HTTP 1下，浏览器对一个域名下最大TCP连接数为6，所以会请求多次。可以用多域名部署解决。这样可以提高同时请求的数目，加快页面图片的获取速度。
- 在HTTP 2下，可以一瞬间加载出来很多资源，因为，HTTP2支持多路复用，可以在一个TCP连接中发送多个HTTP请求。

+++

+++warning 讲讲头部压缩算法
HTTP2的头部压缩是HPACK算法。在客户端和服务器两端建立“字典”，用索引号表示重复的字符串，采用哈夫曼编码来压缩整数和字符串，可以达到50%~90%的高压缩率。

具体来说:

- 在客户端和服务器端使用“首部表”来跟踪和存储之前发送的键值对，对于相同的数据，不再通过每次请求和响应发送；
- 首部表在HTTP/2的连接存续期内始终存在，由客户端和服务器共同渐进地更新；
- 每个新的首部键值对要么被追加到当前表的末尾，要么替换表中之前的值。

![头部压缩](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/bda10d6c69e74996b6505777d29b9a74~tplv-k3u1fbpfcp-zoom-in-crop-mark:3024:0:0:0.awebp)
+++

+++warning 讲讲HTTP3.0
HTTP/3基于UDP协议实现了类似于TCP的多路复用数据流、传输可靠性等功能，这套功能被称为QUIC协议。

![http3.0](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/45a0a2ec0ef143b49d79256cea543418~tplv-k3u1fbpfcp-zoom-in-crop-mark:3024:0:0:0.awebp)

1. 流量控制、传输可靠性功能：QUIC在UDP的基础上增加了一层来保证数据传输可靠性，它提供了数据包重传、拥塞控制、以及其他一些TCP中的特性。
2. 集成TLS加密功能：目前QUIC使用TLS1.3，减少了握手所花费的RTT数。
3. 多路复用：同一物理连接上可以有多个独立的逻辑数据流，实现了数据流的单独传输，解决了TCP的队头阻塞问题。
4. 快速握手：由于基于UDP，可以实现使用0 ~ 1个RTT来建立连接。

![3.0](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/48df233ce8e541efa165160c169b7a70~tplv-k3u1fbpfcp-zoom-in-crop-mark:3024:0:0:0.awebp)
+++

#### HTTPS

+++warning HTTPS握手过程
参考小林coding中的解析
+++

+++warning 讲讲TLS/SSL的工作原理（HTTPS如何保证安全）

TLS/SSL全称安全传输层协议（Transport Layer Security）, 是介于TCP和HTTP之间的一层安全协议，不影响原有的TCP协议和HTTP协议，所以使用HTTPS基本上不需要对HTTP页面进行太多的改造。

TLS/SSL的功能实现主要依赖三类基本算法：散列函数hash、对称加密、非对称加密。这三类算法的作用如下：

1. 基于散列函数验证信息的完整性
2. 对称加密算法采用协商的秘钥对数据加密
3. 非对称加密实现身份认证和秘钥协商

![TLS](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/5696ee8ccb0d44b08b812a7c964695b7~tplv-k3u1fbpfcp-zoom-in-crop-mark:3024:0:0:0.awebp)

（1）散列函数hash
常见的散列函数有MD5、SHA1、SHA256。该函数的特点是单向不可逆，对输入数据非常敏感，输出的长度固定，任何数据的修改都会改变散列函数的结果，可以用于防止信息篡改并验证数据的完整性。

特点：在信息传输过程中，散列函数不能三都实现信息防篡改，由于传输是明文传输，中间人可以修改信息后重新计算信息的摘要，所以需要对传输的信息和信息摘要进行加密。
（2）对称加密
对称加密的方法是，双方使用同一个秘钥对数据进行加密和解密。但是对称加密的存在一个问题，就是如何保证秘钥传输的安全性，因为秘钥还是会通过网络传输的，一旦秘钥被其他人获取到，那么整个加密过程就毫无作用了。 这就要用到非对称加密的方法。

常见的对称加密算法有AES-CBC、DES、3DES、AES-GCM等。相同的秘钥可以用于信息的加密和解密。掌握秘钥才能获取信息，防止信息窃听，其通讯方式是一对一。

特点：对称加密的优势就是信息传输使用一对一，需要共享相同的密码，密码的安全是保证信息安全的基础，服务器和N个客户端通信，需要维持N个密码记录且不能修改密码。
（3）非对称加密
非对称加密的方法是，我们拥有两个秘钥，一个是公钥，一个是私钥。公钥是公开的，私钥是保密的。用私钥加密的数据，只有对应的公钥才能解密，用公钥加密的数据，只有对应的私钥才能解密。我们可以将公钥公布出去，任何想和我们通信的客户， 都可以使用我们提供的公钥对数据进行加密，这样我们就可以使用私钥进行解密，这样就能保证数据的安全了。但是非对称加密有一个缺点就是加密的过程很慢，因此如果每次通信都使用非对称加密的方式的话，反而会造成等待时间过长的问题。

常见的非对称加密算法有RSA、ECC、DH等。秘钥成对出现，一般称为公钥（公开）和私钥（保密）。公钥加密的信息只有私钥可以解开，私钥加密的信息只能公钥解开，因此掌握公钥的不同客户端之间不能相互解密信息，只能和服务器进行加密通信，服务器可以实现一对多的的通信，客户端也可以用来验证掌握私钥的服务器的身份。

特点：非对称加密的特点就是信息一对多，服务器只需要维持一个私钥就可以和多个客户端进行通信，但服务器发出的信息能够被所有的客户端解密，且该算法的计算复杂，加密的速度慢。

综合上述算法特点，TLS/SSL的工作方式就是客户端使用非对称加密与服务器进行通信，实现身份的验证并协商对称加密使用的秘钥。对称加密算法采用协商秘钥对信息以及信息摘要进行加密通信，不同节点之间采用的对称秘钥不同，从而保证信息只能通信双方获取。这样就解决了两个方法各自存在的问题。

+++

+++warning SSL连接断开后如何恢复
Session id：通过将会话时产生的编号再一次传给服务器，若服务器有该记录则可以继续使用
Session Ticket：session ticket 是服务器在上一次对话中发送给客户的，这个 ticket 是加密的，只有服务器可能够解密，里面包含了本次会话的信息，比如对话密钥和加密方法等。这样不管我们的请求是否转移到其他的服务器上，当服务器将 ticket 解密以后，就能够获取上次对话的信息，就不用重新生成对话秘钥了。
+++

+++warning http 和 https 的区别及优缺点？

1. http 是超文本传输协议，信息是明文传输，HTTPS 协议要比 http 协议安全，https 是具有安全性的 ssl 加密传输协议，可防止数据在传输过程中被窃取、改变，确保数据的完整性(当然这种安全性并非绝对的，对于更深入的 Web 安全问题，此处暂且不表)。
2. http 协议的默认端口为 80，https 的默认端口为 443。
3. http 的连接很简单，是无状态的。https 握手阶段比较费时，会使页面加载时间延长 50%，增加 10%~20%的耗电。
4. https 缓存不如 http 高效，会增加数据开销。
5. Https 协议需要 ca 证书，费用较高，功能越强大的证书费用越高。
6. SSL 证书需要绑定 IP，不能再同一个 IP 上绑定多个域名，IPV4 资源支持不了这种消耗。

+++

### TCP/UDP/WebSocket

+++warning TCP三次握手四次挥手
`握手：`

1. 发送端发送SYN标志（我要发送请求）
2. 接收端回复一个SYN/ACK（ok收到，你发吧）
3. 发送端再回复ACK握手结束（ok）

`挥手`

1. 主动关闭方发送FIN（我要关闭请求了）【注意这里如果还有未完毕的请求（未收到对方ACK）会继续发送或接收】
2. 被关闭方回复ACK（知道了，等我这边处理请求完先）
3. 被关闭方发送FIN（处理完了，我也要关闭请求了）
4. 主动关闭方回复ACK（知道了）

:::warning no-icon
如果省略第三次握手，则遇到网络差的情况会阻塞导致再建立一条新的TCP握手请求，等到网络畅通时旧的网络请求会再工作导致bug
:::
+++

+++warning TCP和UDP的区别
TCP是面向有连接的协议，一对一、可靠、面向字节流、提供拥塞控制、提供全双工通信
UDP是面向无连接的协议，一对多、不可靠、面向报文
+++

+++warning TCP/IP / 如何保证数据包传输的有序可靠？
对字节流分段并进行编号然后通过 ACK 回复和超时重发这两个机制来保证。

1. 为了保证数据包的可靠传递，发送方必须把已发送的数据包保留在缓冲区；
2. 并为每个已发送的数据包启动一个超时定时器；
3. 如在定时器超时之前收到了对方发来的应答信息（可能是对本包的应答，也可以是对本包后续包的应答），则释放该数据包占用的缓冲区;
4. 否则，重传该数据包，直到收到应答或重传次数超过规定的最大次数为止。
5. 接收方收到数据包后，先进行CRC校验，如果正确则把数据交给上层协议，然后给发送方发送一个累计应答包，表明该数据已收到，如果接收方正好也有数据要发给发送方，应答包也可方在数据包中捎带过去。

+++

+++warning TCP的拥塞控制机制
TCP的拥塞控制机制主要是以下四种机制：

- 慢启动（慢开始）
- 拥塞避免
- 快速重传
- 快速恢复

1. 慢启动（慢开始）
● 在开始发送的时候设置cwnd = 1（cwnd指的是拥塞窗口）
● 思路：开始的时候不要发送大量数据，而是先测试一下网络的拥塞程度，由小到大增加拥塞窗口的大小。
● 为了防止cwnd增长过大引起网络拥塞，设置一个慢开始门限(ssthresh 状态变量)
  ○ 当cnwd < ssthresh，使用慢开始算法
  ○ 当cnwd = ssthresh，既可使用慢开始算法，也可以使用拥塞避免算法
  ○ 当cnwd > ssthresh，使用拥塞避免算法
2. 拥塞避免
● 拥塞避免未必能够完全避免拥塞，是说在拥塞避免阶段将拥塞窗口控制为按线性增长，使网络不容易出现阻塞。
● 思路： 让拥塞窗口cwnd缓慢的增大，即每经过一个返回时间RTT就把发送方的拥塞控制窗口加一
● 无论是在慢开始阶段还是在拥塞避免阶段，只要发送方判断网络出现拥塞，就把慢开始门限设置为出现拥塞时的发送窗口大小的一半。然后把拥塞窗口设置为1，执行慢开始算法。如图所示:
![a](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/06b60b174bb242b498d244002caded1c~tplv-k3u1fbpfcp-zoom-in-crop-mark:3024:0:0:0.awebp)
其中，判断网络出现拥塞的根据就是没有收到确认，虽然没有收到确认可能是其他原因的分组丢失，但是因为无法判定，所以都当做拥塞来处理。
3. 快速重传
● 快重传要求接收方在收到一个失序的报文段后就立即发出重复确认(为的是使发送方及早知道有报文段没有到达对方)。发送方只要连续收到三个重复确认就立即重传对方尚未收到的报文段，而不必继续等待设置的重传计时器时间到期。
● 由于不需要等待设置的重传计时器到期，能尽早重传未被确认的报文段，能提高整个网络的吞吐量
4. 快速恢复
● 当发送方连续收到三个重复确认时，就执行“乘法减小”算法，把ssthresh门限减半。但是接下去并不执行慢开始算法。
● 考虑到如果网络出现拥塞的话就不会收到好几个重复的确认，所以发送方现在认为网络可能没有出现拥塞。所以此时不执行慢开始算法，而是将cwnd设置为ssthresh的大小，然后执行拥塞避免算法。
![1](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/d0f5339da8c741d19f416cac2af18e4f~tplv-k3u1fbpfcp-zoom-in-crop-mark:3024:0:0:0.awebp)
+++

+++warning TCP的流量控制机制
一般来说，流量控制就是为了让发送方发送数据的速度不要太快，要让接收方来得及接收。TCP采用大小可变的滑动窗口进行流量控制，窗口大小的单位是字节。这里说的窗口大小其实就是每次传输的数据大小。

- 当一个连接建立时，连接的每一端分配一个缓冲区来保存输入的数据，并将缓冲区的大小发送给另一端。
- 当数据到达时，接收方发送确认，其中包含了自己剩余的缓冲区大小。（剩余的缓冲区空间的大小被称为窗口，指出窗口大小的通知称为窗口通告 。接收方在发送的每一确认中都含有一个窗口通告。）
- 如果接收方应用程序读数据的速度能够与数据到达的速度一样快，接收方将在每一确认中发送一个正的窗口通告。
- 如果发送方操作的速度快于接收方，接收到的数据最终将充满接收方的缓冲区，导致接收方通告一个零窗口 。发送方收到一个零窗口通告时，必须停止发送，直到接收方重新通告一个正的窗口。

+++

+++warning 什么是粘包问题，如何解决？
默认情况下, TCP 连接会启⽤延迟传送算法 (Nagle 算法), 在数据发送之前缓存他们. 如果短时间有多个数据发送, 会缓冲到⼀起作⼀次发送 (缓冲⼤⼩⻅ socket.bufferSize ), 这样可以减少 IO 消耗提⾼性能.
粘包情况有两种，一种是粘在一起的包都是完整的数据包，另一种情况是粘在一起的包有不完整的包。

为了避免粘包现象，可采取以下几种措施：

1. 进⾏封包/拆包：封包/拆包是⽬前业内常⻅的解决⽅案了。即给每个数据包在发送之前, 于其前/后放⼀些有特征的数据, 然后收到数据的时 候根据特征数据分割出来各个数据包。
2. 关闭 Nagle 算法, 在 Node.js 中你可以通过 socket.setNoDelay() ⽅法来关闭 Nagle 算法, 让每⼀次 send 都不缓冲直接发送
3. 多次发送之前间隔⼀个等待时间

以上提到的三种措施，都有其不足之处。

`不足`

1. 第二种该⽅法⽐较适⽤于每次发送的数据都⽐较⼤ (但不是⽂件那么⼤), 并且频率不是特别⾼的场景。如果是每次发送的数据量⽐较⼩, 并且频率特别⾼的, 关闭 Nagle 纯属⾃废武功。另外, 该⽅法不适⽤于⽹络较差的情况, 因为 Nagle 算法是在服务端进⾏的包合并情况, 但是如果短时间内客户端的⽹络情况不好, 或者应⽤层由于某些原因不能及时将 TCP 的数据 recv, 就会造成多个包在客户端缓冲从⽽粘包的情况。 (如果是在稳定的机房内部通信那么这个概率是⽐较⼩可以选择忽略的)  
2. 第三种对于⽐较频繁的场景⽽⾔传输效率实在太低，不过⼏乎不⽤做什么处理.

一种比较周全的对策是：接收方创建一预处理线程，对接收到的数据包进行预处理，将粘连的包分开。实验证明这种方法是高效可行的。
:::warning no-icon
黏包只在在流传输中出现，UDP不会出现粘包，因为它有消息边界：在每个UDP包中就有了消息头（消息来源地址，端⼝等信息），这样对于接收端来说就容易进⾏区分处理了。传输协议把数据当作⼀条独⽴的消息在⽹上传输，接收端只能接收独⽴的消息。接收端⼀次只能接收发送端发出的⼀个数据包,如果⼀次接受数据的⼤⼩⼩于发送端⼀次发送的数据⼤⼩，就会丢失⼀部分数据，即使丢失，接受端也不会分两次去接收。
如果是传输⽂件的话, 那么根本不⽤处理粘包的问题, 来⼀个包拼⼀个包就好了。但是如果是多条消息, 或者是别的⽤途的数据那么就需要处理粘包.
:::
+++

+++warning A、B 机器正常连接后，B 机器突然重启，问 A 此时处于 TCP 什么状态?
因为 B 会在重启之后进入 tcp 状态机的 listen 状态，只要当 a 重新发送一个数据包（无论是 syn 包或者是应用数据），b 端应该会主动发送一个带 rst 位的重置包来进行连接重置，所以 a 应该在 syn_sent 状态
+++

## 浏览器

### 组成

+++info 浏览器的主要组成部分

- ⽤户界⾯ - 包括地址栏、前进/后退按钮、书签菜单等。除了浏览器主窗⼝显示的您请求的⻚⾯外，其他显示的各个部分都属于⽤户界⾯。
- 浏览器引擎 - 在⽤户界⾯和呈现引擎之间传送指令。
- 呈现引擎 - 负责显示请求的内容。如果请求的内容是 HTML，它就负责解析 HTML 和 CSS 内容，并将解析后的内容显示在屏幕上。
- ⽹络 - ⽤于⽹络调⽤，⽐如 HTTP 请求。其接⼝与平台⽆关，并为所有平台提供底层实现。
- ⽤户界⾯后端 - ⽤于绘制基本的窗⼝⼩部件，⽐如组合框和窗⼝。其公开了与平台⽆关的通⽤接⼝，⽽在底层使⽤操作系统的⽤户界⾯⽅法。
- JavaScript 解释器。⽤于解析和执⾏ JavaScript 代码。
- 数据存储 - 这是持久层。浏览器需要在硬盘上保存各种数据，例如 Cookie。新的 HTML 规范 (HTML5) 定义了“⽹络数据库”，这是⼀个完整（但是轻便）的浏览器内数据库。

+++

+++info 常见浏览器的内核

1. IE 浏览器内核：Trident 内核，也是俗称的 IE 内核；
2. Chrome 浏览器内核：统称为 Chromium 内核或 Chrome 内核，以前是 Webkit 内核，现在是 Blink内核；
3. Firefox 浏览器内核：Gecko 内核，俗称 Firefox 内核；
4. Safari 浏览器内核：Webkit 内核；
5. Opera 浏览器内核：最初是自己的 Presto 内核，后来加入谷歌大军，从 Webkit 又到了 Blink 内核；
6. 360浏览器、猎豹浏览器内核：IE + Chrome 双内核；
7. 搜狗、遨游、QQ 浏览器内核：Trident（兼容模式）+ Webkit（高速模式）；
8. 百度浏览器、世界之窗内核：IE 内核；
9. 2345浏览器内核：好像以前是 IE 内核，现在也是 IE + Chrome 双内核了；
10. UC 浏览器内核：这个众口不一，UC 说是他们自己研发的 U3 内核，但好像还是基于 Webkit 和 Trident ，还有说是基于火狐内核。

+++

+++info 浏览器的进程有哪些
![进程](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/83e928a4f95d4ebe91d0881b5b2cf94b~tplv-k3u1fbpfcp-zoom-in-crop-mark:3024:0:0:0.awebp)

- 1 个浏览器主进程
- 1 个 GPU 进程
- 1 个网络进程
- 多个渲染进程
- 多个插件进程

这些进程的功能：

- 浏览器进程：主要负责界面显示、用户交互、子进程管理，同时提供存储等功能。
- 渲染进程：核心任务是将 HTML、CSS 和 JavaScript 转换为用户可以与之交互的网页，排版引擎 Blink 和 JavaScript 引擎 V8 都是运行在该进程中，默认情况下，Chrome 会为每个 Tab 标签创建一个渲染进程。出于安全考虑，渲染进程都是运行在沙箱模式下。
- GPU 进程：其实， GPU 的使用初衷是为了实现 3D CSS 的效果，只是随后网页、Chrome 的 UI 界面都选择采用 GPU 来绘制，这使得 GPU 成为浏览器普遍的需求。最后，Chrome 在其多进程架构上也引入了 GPU 进程。
- 网络进程：主要负责页面的网络资源加载，之前是作为一个模块运行在浏览器进程里面的，直至最近才独立出来，成为一个单独的进程。
- 插件进程：主要是负责插件的运行，因插件易崩溃，所以需要通过插件进程来隔离，以保证插件进程崩溃不会对浏览器和页面造成影响。

所以，打开一个网页，最少需要四个进程：1 个网络进程、1 个浏览器进程、1 个 GPU 进程以及 1 个渲染进程。如果打开的页面有运行插件的话，还需要再加上 1 个插件进程。

虽然多进程模型提升了浏览器的稳定性、流畅性和安全性，但同样不可避免地带来了一些问题：

- 更高的资源占用：因为每个进程都会包含公共基础结构的副本（如 JavaScript 运行环境），这就意味着浏览器会消耗更多的内存资源。
- 更复杂的体系架构：浏览器各模块之间耦合性高、扩展性差等问题，会导致现在的架构已经很难适应新的需求了。

+++

+++info 渲染进程的线程有哪些
![渲染](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/d6e583f59dc742b9b4e88cf3a3b0f1d4~tplv-k3u1fbpfcp-zoom-in-crop-mark:3024:0:0:0.awebp)

1. GUI渲染线程
负责渲染浏览器页面，解析HTML、CSS，构建DOM树、构建CSSOM树、构建渲染树和绘制页面；当界面需要重绘或由于某种操作引发回流时，该线程就会执行。
:::warning no-icon
注意：GUI渲染线程和JS引擎线程是互斥的，当JS引擎执行时GUI线程会被挂起，GUI更新会被保存在一个队列中等到JS引擎空闲时立即被执行。
:::

2. JS引擎线程
JS引擎线程也称为JS内核，负责处理Javascript脚本程序，解析Javascript脚本，运行代码；JS引擎线程一直等待着任务队列中任务的到来，然后加以处理，一个Tab页中无论什么时候都只有一个JS引擎线程在运行JS程序；
:::warning no-icon
注意：GUI渲染线程与JS引擎线程的互斥关系，所以如果JS执行的时间过长，会造成页面的渲染不连贯，导致页面渲染加载阻塞。
:::

3. 时间触发线程
时间触发线程属于浏览器而不是JS引擎，用来控制事件循环；当JS引擎执行代码块如setTimeOut时（也可是来自浏览器内核的其他线程,如鼠标点击、AJAX异步请求等），会将对应任务添加到事件触发线程中；当对应的事件符合触发条件被触发时，该线程会把事件添加到待处理队列的队尾，等待JS引擎的处理；
:::warning no-icon
注意：由于JS的单线程关系，所以这些待处理队列中的事件都得排队等待JS引擎处理（当JS引擎空闲时才会去执行）；
:::

4. 定时器触发进程
定时器触发进程即setInterval与setTimeout所在线程；浏览器定时计数器并不是由JS引擎计数的，因为JS引擎是单线程的，如果处于阻塞线程状态就会影响记计时的准确性；因此使用单独线程来计时并触发定时器，计时完毕后，添加到事件队列中，等待JS引擎空闲后执行，所以定时器中的任务在设定的时间点不一定能够准时执行，定时器只是在指定时间点将任务添加到事件队列中；
:::warning no-icon
注意：W3C在HTML标准中规定，定时器的定时时间不能小于4ms，如果是小于4ms，则默认为4ms。
:::

5. 异步http请求线程
XMLHttpRequest连接后通过浏览器新开一个线程请求；
检测到状态变更时，如果设置有回调函数，异步线程就产生状态变更事件，将回调函数放入事件队列中，等待JS引擎空闲后执行；
+++

### 机制

+++info 渲染机制、回流与重绘、如何避免
![渲染](https://user-images.githubusercontent.com/17002181/126033732-d5002255-1c88-4dee-9371-da166aacdca9.png)
浏览器渲染大致分为四个阶段，其中在解析 HTML 后，会依次进入 Layout 和 Paint 阶段。样式或节点的更改，以及对布局信息的访问等，都有可能导致重排和重绘。而重排和重绘的过程在主线程中进行，这意味着不合理的重排重绘会导致渲染卡顿，用户交互滞后等性能问题。

1. Parse HTML：相关引擎分别解析文档和样式表，生成 DOM 和 CSSOM ，最终合成为 Render 树。 浏览器采用流式布局模型（Flow Based Layout）
2. Layout：浏览器通过 Render 树中的信息，以递归的形式计算出每个节点的尺寸大小和在页面中的具体位置。
3. Paint：浏览器将 Render 树中的节点转换成在屏幕上绘制实际像素的指令，这个过程发生在多个图层上。
4. 浏览器将所有层按照一定顺序合并为一个图层并绘制在屏幕上。

若DOM或CSSOM被修改会导致浏览器重复执行Layout和Paint过程

`回流`
布局或者几何属性改变时触发回流。回流是影响浏览器性能的关键因素，因为其变化涉及到部分页面（或是整个页面）的布局更新。一个元素的回流可能会导致其素有子元素以及 DOM 中紧随其后的节点、祖先节点元素的随后的回流。大部分的回流将导致页面的重新渲染。回流必定会发生重绘，重绘不一定会引发回流。
`重绘`
由于节点的集合属性发生改变或者由于样式改变而不会影响布局的，成为重绘，例如 outline、visibility、color、background-color 等

减少回流和重绘

`CSS`

- 使用 transform 代替 top，开启硬件加速
- 使用 visibility 替换 display: none，前者引起重绘，后者引发回流
- 避免使用 table 布局
- 尽可能在 DOM 树的最末端改变 class
- 避免设置多层内联样式，CSS 选择符从右往左匹配查找，避免节点层级过多
- 将动画效果应用到 position 属性为 absolute 或 fixed 的元素上，避免影响其他元素的布局
- 避免使用 CSS 表达式，可能会引发回流

`Javascript`

- 避免频繁操作样式，修改 class 最好
- 避免频繁操作 DOM，合并多次修改为一次(虚拟DOM、DocumentFragment)
- 避免频繁读取会引发回流/重绘的属性，将结果缓存（clientTop）
- 对用户改变窗口的操作进行防抖处理

+++

+++info 什么是文档的预解析？
Webkit 和 Firefox 都做了这个优化，当执行 JavaScript 脚本时，另一个线程解析剩下的文档，并加载后面需要通过网络加载的资源。这种方式可以使资源并行加载从而使整体速度更快。需要注意的是，预解析并不改变 DOM 树，它将这个工作留给主解析过程，自己只解析外部资源的引用，比如外部脚本、样式表及图片。
+++

+++info 如何优化关键渲染路径？
为尽快完成首次渲染，我们需要最大限度减小以下三种可变因素：

1. 关键资源的数量。
2. 关键路径长度。
3. 关键字节的数量。

关键资源是可能阻止网页首次渲染的资源。这些资源越少，浏览器的工作量就越小，对 CPU 以及其他资源的占用也就越少。同样，关键路径长度受所有关键资源与其字节大小之间依赖关系图的影响：某些资源只能在上一资源处理完毕之后才能开始下载，并且资源越大，下载所需的往返次数就越多。最后，浏览器需要下载的关键字节越少，处理内容并让其出现在屏幕上的速度就越快。要减少字节数，我们可以减少资源数（将它们删除或设为非关键资源），此外还要压缩和优化各项资源，确保最大限度减小传送大小。

优化关键渲染路径的常规步骤如下：

1. 对关键路径进行分析和特性描述：资源数、字节数、长度。
2. 最大限度减少关键资源的数量：删除它们，延迟它们的下载，将它们标记为异步等。
3. 优化关键字节数以缩短下载时间（往返次数）。
4. 优化其余关键资源的加载顺序：您需要尽早下载所有关键资产，以缩短关键路径长度

+++

+++info 说下进程、线程和协程
进程是应用程序运行的载体，是操作系统资源分配的最小单位。

线程是程序执行中一个单一的顺序控制流程，是CPU调度的最小单位。一个进程可以有一个或多个线程，各个线程之间共享程序的内存空间(也就是所在进程的内存空间)。一个标准的线程由线程ID、当前指令指针(PC)、寄存器和堆栈组成。而进程由内存空间(代码、数据、进程空间、打开的文件)和一个或多个线程组成。

协程是一种基于线程之上，但又比线程更加轻量级的存在，这种由程序员自己写程序来管理的轻量级线程叫做『用户空间线程』，具有对内核来说不可见的特性。

进程和线程的区别与联系
【区别】：
调度：进程切换比线程切换的开销要大。线程是CPU调度的基本单位，线程的切换不会引起进程切换，但某个进程中的线程切换到另一个进程中的线程时，会引起进程切换。
拥有资源：进程是拥有资源的一个独立单位，线程不拥有系统资源，但可以访问隶属于进程的资源。
通信方面：线程间可以通过直接共享同一进程中的资源，而进程通信需要借助 进程间通信。
系统开销：在创建或撤消进程时，由于系统都要为之分配和回收资源，导致系统的开销明显大于创建或撤消线程时的开销。但是进程有独立的地址空间，一个进程崩溃后，在保护模式下不会对其它进程产生影响，而线程只是一个进程中的不同执行路径。线程有自己的堆栈和局部变量，但线程之间没有单独的地址空间，一个进程死掉就等于所有的线程死掉，所以多进程的程序要比多线程的程序健壮，但在进程切换时，耗费资源较大，效率要差一些。
【联系】：
一个线程只能属于一个进程，而一个进程可以有多个线程，但至少有一个线程；
资源分配给进程，同一进程的所有线程共享该进程的所有资源；
处理机分给线程，即真正在处理机上运行的是线程；
线程在执行过程中，需要协作同步。不同进程的线程间要利用消息通信的办法实现同步。

+++

+++info 进程之前的通信方式

1. 管道通信
管道是一种最基本的进程间通信机制。管道就是操作系统在内核中开辟的一段缓冲区，进程1可以将需要交互的数据拷贝到这段缓冲区，进程2就可以读取了。
管道的特点：
(1)只能单向通信
(2)只能血缘关系的进程进行通信
(3)依赖于文件系统
(4)生命周期随进程
(5)面向字节流的服务
(6)管道内部提供了同步机制

2. 消息队列通信
消息队列就是一个消息的列表。用户可以在消息队列中添加消息、读取消息等。消息队列提供了一种从一个进程向另一个进程发送一个数据块的方法。 每个数据块都被认为含有一个类型，接收进程可以独立地接收含有不同类型的数据结构。可以通过发送消息来避免命名管道的同步和阻塞问题。但是消息队列与命名管道一样，每个数据块都有一个最大长度的限制。
使用消息队列进行进程间通信，可能会收到数据块最大长度的限制约束等，这也是这种通信方式的缺点。如果频繁的发生进程间的通信行为，那么进程需要频繁地读取队列中的数据到内存，相当于间接地从一个进程拷贝到另一个进程，这需要花费时间。

3. 信号量通信
共享内存最大的问题就是多进程竞争内存的问题，就像类似于线程安全问题。我们可以使用信号量来解决这个问题。信号量的本质就是一个计数器，用来实现进程之间的互斥与同步。例如信号量的初始值是 1，然后 a 进程来访问内存1的时候，我们就把信号量的值设为 0，然后进程b 也要来访问内存1的时候，看到信号量的值为 0 就知道已经有进程在访问内存1了，这个时候进程 b 就会访问不了内存1。所以说，信号量也是进程之间的一种通信方式。

4. 信号通信
信号（Signals ）是Unix系统中使用的最古老的进程间通信的方法之一。操作系统通过信号来通知进程系统中发生了某种预先规定好的事件（一组事件中的一个），它也是用户进程之间通信和同步的一种原始机制。

5. 共享内存通信
共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问（使多个进程可以访问同一块内存空间）。共享内存是最快的 IPC 方式，它是针对其他进程间通信方式运行效率低而专门设计的。它往往与其他通信机制，如信号量，配合使用，来实现进程间的同步和通信。

6. 套接字通信
上面我们说的共享内存、管道、信号量、消息队列，他们都是多个进程在一台主机之间的通信，那两个相隔几千里的进程能够进行通信吗？答是必须的，这个时候 Socket 这家伙就派上用场了，例如我们平时通过浏览器发起一个 http 请求，然后服务器给你返回对应的数据，这种就是采用 Socket 的通信方式了。

+++

+++info 父进程或子进程的死亡是否会影响对方? 什么是孤儿进程?僵尸进程?
子进程死亡不会影响父进程，不过子进程死亡时，会向它的父进程发送死亡信号。反之父进程死亡，一般情况下子进程也会随之死亡，但如果此时子进程处于可运行状态、僵死状态等等的话，子进程将被 init 进程收养，从而成为孤儿进程。
子进程死亡的时候（处于“终止状态”），父进程没有及时调用 wait() 或 waitpid() 来返回死亡进程的相关信息，此时子进程还有一个 PCB 残留在进程表中，被称为僵尸进程。
+++

+++info 死锁产生的原因？ 如果解决死锁的问题？
所谓死锁，是指多个进程在运行过程中因争夺资源而造成的一种僵局，当进程处于这种僵持状态时，若无外力作用，它们都将无法再向前推进。

系统中的资源可以分为两类：
● 可剥夺资源，是指某进程在获得这类资源后，该资源可以再被其他进程或系统剥夺，CPU和主存均属于可剥夺性资源；
● 不可剥夺资源，当系统把这类资源分配给某进程后，再不能强行收回，只能在进程用完后自行释放，如磁带机、打印机等。

产生死锁的原因：
（1）竞争资源
● 产生死锁中的竞争资源之一指的是竞争不可剥夺资源（例如：系统中只有一台打印机，可供进程P1使用，假定P1已占用了打印机，若P2继续要求打印机打印将阻塞）
● 产生死锁中的竞争资源另外一种资源指的是竞争临时资源（临时资源包括硬件中断、信号、消息、缓冲区内的消息等），通常消息通信顺序进行不当，则会产生死锁
（2）进程间推进顺序非法
若P1保持了资源R1，P2保持了资源R2，系统处于不安全状态，因为这两个进程再向前推进，便可能发生死锁。例如，当P1运行到P1：Request（R2）时，将因R2已被P2占用而阻塞；当P2运行到P2：Request（R1）时，也将因R1已被P1占用而阻塞，于是发生进程死锁

产生死锁的必要条件：

- 互斥条件：进程要求对所分配的资源进行排它性控制，即在一段时间内某资源仅为一进程所占用。
- 请求和保持条件：当进程因请求资源而阻塞时，对已获得的资源保持不放。
- 不剥夺条件：进程已获得的资源在未使用完之前，不能剥夺，只能在使用完时由自己释放。
- 环路等待条件：在发生死锁时，必然存在一个进程——资源的环形链。

预防死锁的方法：

- 资源一次性分配：一次性分配所有资源，这样就不会再有请求了（破坏请求条件）
- 只要有一个资源得不到分配，也不给这个进程分配其他的资源（破坏请保持条件）
- 可剥夺资源：即当某进程获得了部分资源，但得不到其它资源，则释放已占有的资源（破坏不可剥夺条件）
- 资源有序分配法：系统给每类资源赋予一个编号，每一个进程按编号递增的顺序请求资源，释放则相反（破坏环路等待条件）

+++

### 网络相关

+++info 一个页面从输入URL到页面加载显示完成，这个过程中都发生了什么？
`请求：`

1. 浏览器会开启一个线程来处理这个请求，如果是关键字或不合法url则启动对应搜索引擎，如果输入是正确url则首先对本地缓存进行判断看是否命中强缓存，是则直接用缓存资源，否则往下走
2. DNS解析：浏览器按照`本地缓存->本地DNS服务器->根域名服务器->顶级域名服务器->权威域名服务器`顺序获取IP地址(用户向本地 DNS 服务器发起请求属于递归请求，本地 DNS 服务器向各级域名服务器发起请求属于迭代请求)。
3. 当浏览器得到 IP 地址后，数据传输还需要知道目的主机 MAC 地址，因为应用层下发数据给传输层，TCP 协议会指定源端口号和目的端口号，然后下发给网络层。网络层会将本机地址作为源地址，获取的 IP 地址作为目的地址。然后将下发给数据链路层，数据链路层的发送需要加入通信双方的 MAC 地址，本机的 MAC 地址作为源 MAC 地址，目的 MAC 地址需要分情况处理。通过将 IP 地址与本机的子网掩码相与，可以判断是否与请求主机在同一个子网里，如果在同一个子网里，可以使用 APR 协议获取到目的主机的 MAC 地址，如果不在一个子网里，那么请求应该转发给网关，由它代为转发，此时同样可以通过 ARP 协议来获取网关的 MAC 地址，此时目的主机的 MAC 地址应该为网关的地址。
4. 浏览器与远程 Web 服务器通过 TCP 三次握手协商来建立一个 TCP/IP 连接。该握手包括一个同步报文，一个同步-应答报文和一个应答报文，这三个报文在浏览器和服务器之间传递。该握手首先由客户端尝试建立起通信，而后服务器应答并接受客户端的请求，最后由客户端发出该请求已经被接受的报文。
5. 如果使用的是 HTTPS 协议，在通信前还存在 TLS 的一个四次握手的过程。首先由客户端向服务器端发送使用的协议的版本号、一个随机数和可以使用的加密方法。服务器端收到后，确认加密的方法，也向客户端发送一个随机数和自己的数字证书。客户端收到后，首先检查数字证书是否有效，如果有效，则再生成一个随机数，并使用证书中的公钥对随机数加密，然后发送给服务器端，并且还会提供一个前面所有内容的 hash 值供服务器端检验。服务器端接收后，使用自己的私钥对数据解密，同时向客户端发送一个前面所有内容的 hash 值供客户端检验。这个时候双方都有了三个随机数，按照之前所约定的加密方法，使用这三个随机数生成一把会话秘钥，以后双方通信前，就使用这个会话秘钥对数据进行加密后再传输。
6. 此时， Web 服务器提供资源服务，客户端开始下载资源。

![HTTPS握手](https://user-images.githubusercontent.com/17002181/131222941-02fc347d-32c1-41ff-80b1-4f47a23f833f.png)

`渲染：`

![渲染](https://user-images.githubusercontent.com/15681693/131242132-b299c8ec-1c61-4dc0-86b8-62b3bbdae612.png)

1. 解析
解析收到的文档，根据文档构建一颗DOM树，DOM 树是由 DOM元素及属性节点组成的。
然后对 CSS 进行解析，生成CSSOM规则树
根据 DOM 树和 CSSOM 规则树构建 Render Tree。渲染树的节点被称为渲染对象，渲染对象是一个包含有颜色和大小等属性的矩形，渲染对象和DOM 对象相对应，但这种对应关系不是一对一的，不可见的 DOM 元素不会被插入渲染树。
下载JS脚本、图片等资源
2. 布局
接着就会根据渲染树来进行布局（也可以叫做回流）。这一阶段浏览器要做的事情就是要弄清楚各个节点在页面中的确切位置和大小。通常这一行为也被称为“自动重排”。
3. 绘制
布局阶段结束后是绘制阶段，比那里渲染树并调用对象的 paint 方法将它们的内容显示在屏幕上，绘制使用 UI 基础组件。为了更好的用户体验，渲染引擎会尽可能早的将内容呈现到屏幕上，并不会等到所有的 html 解析完成之后再去构建和布局 render tree。它是解析完一部分内容就显示一部分内容，同时可能还在网络下载其余内容。

`JS引擎解析：`

1. 创建window对象：window对象也叫全局执行环境，当页面产生时就被创建，所有的全局变量和函数都属于window的属性和方法，而DOM Tree也会映射在window的doucment对象上。当关闭网页或者关闭浏览器时，全局执行环境会被销毁。
2. 加载文件：完成js引擎分析它的语法与词法是否合法，如果合法进入预编译
3. 预编译：在预编译的过程中，浏览器会寻找全局变量声明，把它作为window的属性加入到window对象中，并给变量赋值为'undefined'；寻找全局函数声明，把它作为window的方法加入到window对象中，并将函数体赋值给他（匿名函数是不参与预编译的，因为它是变量）。而变量提升作为不合理的地方在ES6中已经解决了，函数提升还存在。
4. 解释执行：执行到变量就赋值，如果变量没有被定义，也就没有被预编译直接赋值，在ES5非严格模式下这个变量会成为window的一个属性，也就是成为全局变量。string、int这样的值就是直接把值放在变量的存储空间里，object对象就是把指针指向变量的存储空间。函数执行，就将函数的环境推入一个环境的栈中，执行完成后再弹出，控制权交还给之前的环境。JS作用域其实就是这样的执行流机制实现的。

`TCP四次挥手：`
最后一步是 TCP 断开连接的四次挥手过程。若客户端认为数据发送完成，则它需要向服务端发送连接释放请求。服务端收到连接释放请求后，会告诉应用层要释放 TCP 链接。然后会发送 ACK 包，并进入 CLOSE_WAIT 状态，此时表明客户端到服务端的连接已经释放，不再接收客户端发的数据了。但是因为 TCP 连接是双向的，所以服务端仍旧可以发送数据给客户端。服务端如果此时还有没发完的数据会继续发送，完毕后会向客户端发送连接释放请求，然后服务端便进入 LAST-ACK 状态。客户端收到释放请求后，向服务端发送确认应答，此时客户端进入 TIME-WAIT 状态。该状态会持续 2MSL（最大段生存期，指报文段在网络中生存的时间，超时会被抛弃） 时间，若该时间段内没有服务端的重发请求的话，就进入 CLOSED 状态。当服务端收到确认应答后，也便进入 CLOSED 状态。
+++

+++info 前端如何上传大文件
`前端`
断点续传，利用Blob.prototype.slice方法返回原文件的某个切片，并将切片通过http并发上传，同时要注意记录切片顺序和最大数量信息
`后端`
在切片接收达到最大数量时即开始合并切片，可以使用nodejs 的api fs.appendFileSync,先创建一个最终文件再逐步合并到此文件中
+++

+++info 同源策略以及如何跨域
同源策略：协议域名端口相同才可以成功发送请求(跨域请求可以发出和响应，但不成功),跨域是浏览器的安全特性，与其他无关
跨域：

1. CORS：服务端设置Access-Control-Allow-Origin
不会触发预检请求的称为简单请求。当请求满足以下条件时就是一个简单请求：
请求方法：GET、HEAD、POST。
请求头：Accept、Accept-Language、Content-Language、Content-Type。
Content-Type 仅支持：application/x-www-form-urlencoded、multipart/form-data、text/plain。
当一个请求不满足以上简单请求的条件时，浏览器会自动向服务端发送一个 OPTIONS 请求，通过服务端返回的 Access-Control-Allow-*判定请求是否被允许。
CORS 引入了以下几个以 Access-Control-Allow-* 开头：
Access-Control-Allow-Origin 表示允许的来源
Access-Control-Allow-Methods 表示允许的请求方法
Access-Control-Allow-Headers 表示允许的请求头
Access-Control-Allow-Credentials 表示允许携带认证信息
当请求符合响应头的这些条件时，浏览器才会发送并响应正式的请求。
2. 反向代理：依赖同源的服务端对请求做一个转发处理，将请求从跨域请求转换成同源请求。反向代理的实现方式为在页面同域下配置一套反向代理服务，页面请求同域的服务端，服务端请求上游的实际的服务端，之后将结果返回给前端。
3. JSONP：通过script标签get请求某个api，不同于上面两个方法，该方法需要前后端配合实现

非常用：

1. postMessage：即在两个 origin 下分别部署一套页面 A 与 B，A 页面通过 iframe 加载 B 页面并监听消息，B 页面发送消息。
2. window.name：主要是利用 window.name 页面跳转不改变的特性实现跨域，即 iframe 加载一个跨域页面，设置 window.name，跳转到同域页面，可以通过 $('iframe').contentWindow.name 拿到跨域页面的数据。
3. document.domain:可将相同一级域名下的子域名页面的 document.domain 设置为一级域名实现跨域。可将同域不同端口的 document.domain 设置为同域名实现跨域（端口被置为 null）。

另外：

1. LocalStorage / SessionStorage 跨域
LocalStorage 和 SessionStorage 同样受到同源策略的限制。而跨域读写的方式也可以使用前文提到的 postMessage。
2. 跨域与监控
前端项目在统计前端报错监控时会遇到上报的内容只有 Script Error 的问题。这个问题也是由同源策略引起。在` <script> `标签上添加 crossorigin="anonymous" 并且返回的 JS 文件响应头加上 Access-Control-Allow-Origin: * 即可捕捉到完整的错误堆栈。
3. 跨域与图片
前端项目在图片处理时可能会遇到图片绘制到 Canvas 上之后却不能读取像素或导出 base64 的问题。这个问题也是由同源策略引起。解决方式和上文相同，给图片添加 crossorigin="anonymous" 并在返回的图片文件响应头加上 Access-Control-Allow-Origin: * 即可解决。
+++

+++info 如何实现浏览器标签页之间的通信
`中介者模式`

1. 使用WebSocket将消息发送给服务器再在推给另一个客户端
2. 调用本地存储如localStorage传递数据

`发布订阅者`

1. 调用webWorker的postMessage

+++

+++info 正向代理和反向代理
正向代理：
客户端想获得一个服务器的数据，但是因为种种原因无法直接获取。于是客户端设置了一个代理服务器，并且指定目标服务器，之后代理服务器向目标服务器转交请求并将获得的内容发送给客户端。这样本质上起到了对真实服务器隐藏真实客户端的目的。实现正向代理需要修改客户端，比如修改浏览器配置。
反向代理：
服务器为了能够将工作负载分不到多个服务器来提高网站性能 (负载均衡)等目的，当其受到请求后，会首先根据转发规则来确定请求应该被转发到哪个服务器上，然后将请求转发到对应的真实服务器上。这样本质上起到了对客户端隐藏真实服务器的作用。
一般使用反向代理后，需要通过修改 DNS 让域名解析到代理服务器 IP，这时浏览器无法察觉到真正服务器的存在，当然也就不需要修改配置了。

![代理](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/97e92248f2654185808f80b65f3ca0f6~tplv-k3u1fbpfcp-zoom-in-crop-mark:3024:0:0:0.awebp)
正向代理和反向代理的结构是一样的，都是 client-proxy-server 的结构，它们主要的区别就在于中间这个 proxy 是哪一方设置的。在正向代理中，proxy 是 client 设置的，用来隐藏 client；而在反向代理中，proxy 是 server 设置的，用来隐藏 server。
+++

+++info 讲讲CDN负载均衡
CDN 是一个内容分发网络，通过对源网站资源的缓存，利用本身多台位于不同地域、不同运营商的服务器，向用户提供资源就近访问的功能。用户的请求并不是直接发送给源网站，而是发送给 CDN 服务器，由 CDN 服务器将请求定位到最近的含有该资源的服务器上去请求。这样有利于提高网站的访问速度，同时通过这种方式也减轻了源服务器的访问压力。
CDN访问过程：

1. 用户输入访问的域名,操作系统向 LocalDns 查询域名的 ip 地址
2. LocalDns 向 ROOT DNS 查询域名的授权服务器(这里假设 LocalDns 缓存过期)，ROOT DNS 将域名授权 dns 记录回应给 LocalDns
3. LocalDns 得到域名的授权 dns 记录后,继续向域名授权 dns 查询域名的 ip 地址域名授权 dns 查询域名记录后(一般是 CNAME )，回应给 LocalDns
4. LocalDns 得到域名记录后,向智能调度 DNS 查询域名的 ip 地址，智能调度 DNS 根据一定的算法和策略(比如静态拓扑，容量等),将最适合的 CDN 节点 ip 地址回应给 LocalDns
5. LocalDns 将得到的域名 ip 地址，回应给 用户端，用户得到域名 ip 地址后，访问站点服务器
6. CDN 节点服务器应答请求，将内容返回给客户端.(缓存服务器一方面在本地进行保存，以备以后使用，二方面把获取的数据返回给客户端，完成数据服务过程)

+++

+++info localhost:3000 与 localhost:5000 的 cookie 信息是否共享
根据同源策略，cookie 是区分端口的，但是浏览器实现来说，“cookie 区分域，而不区分端口，也就是说，同一个 ip 下的多个端口下的 cookie 是共享的！不同协议 http 和 https，也可以共享 但是带有 Secure 属性的不能被 http 共享 带有 HttpOnly 属性的 cookie 无法被 document.cookie 访问
+++

+++info 为什么通常在发送数据埋点请求的时候使用的是 1x1 像素的透明 gif 图片

1. 能够完成整个 HTTP 请求+响应（尽管不需要响应内容）
2. 触发 GET 请求之后不需要获取和处理数据、服务器也不需要发送数据
3. 跨域友好
4. 执行过程无阻塞
5. 相比 XMLHttpRequest 对象发送 GET 请求，性能上更好
6. GIF的最低合法体积最小（最小的BMP文件需要74个字节，PNG需要67个字节，而合法的GIF，只需要43个字节）

+++

+++info localhost:3000 与 localhost:5000 的 cookie 信息是否共享
根据同源策略，cookie 是区分端口的，但是浏览器实现来说，“cookie 区分域，而不区分端口，也就是说，同一个 ip 下的多个端口下的 cookie 是共享的！不同协议 http 和 https，也可以共享 但是带有 Secure 属性的不能被 http 共享 带有 HttpOnly 属性的 cookie 无法被 document.cookie 访问
+++

### 安全

+++danger 接口如何防刷

1. 网关控制流量洪峰，对一个事件段内出现流量异常，可以拒绝请求
2. 源ip请求个数限制，对请求来源的ip请求个数做限制
3. http请求头信息校验，如host，User-Agent，Referer
4. 对用户唯一身份uid进行限制和校验。id的格式、时效性
5. 前后端协议采用二进制的方式进行交互或者协议采用签名机制
6. 人机验证码、短信、滑块验证之类的

+++

+++danger cookie 和 token 都存放在 header 中，为什么不会劫持 token？

1. token不是防止XSS的，而是为了防止CSRF的
2. CSRF攻击的原因是浏览器会自动带上cookie，而浏览器不会自动带上token

+++

+++danger 介绍token的实现

1. 需要一个secret（随机数）
2. 后端利用secret和加密算法(如：HMAC-SHA256)对payload(如账号密码)生成一个字符串(token)返回前端
3. 前端每次request在header中带上token
4. 4.后端用同样的算法解密

+++

+++danger 常见的网络攻击
参考站内贴子`网络攻击`(https://evilmood.github.io/mublog/core/%E7%BD%91%E8%B7%AF%E6%94%BB%E5%87%BB/)
+++

### 存储

+++success web存储方式与特性
| 存储           | 大小 | 特性                           |
| -------------- | ---- | ------------------------------ |
| cookie         | 4KB  | 设置时间内有效，发送请求时携带 |
| localStorage   | 5MB  | 持久存储                       |
| sessionStorage | 5MB  | 关闭页面自动删除               |
| indexDB        | 无限 | 数据库                         |
+++

+++success 谈谈cookie的缺点
缺点：

1. 大小不能超过4KB
2. cookie被人拦截后可以直接使用

+++

+++success 强缓存和协商缓存

![缓存](https://user-images.githubusercontent.com/13888962/125894860-a0b9eecd-03b6-49ce-9612-9705b1fb6e78.png)
浏览器请求时会执行强缓存，若本地没有缓存则会发送请求进行协商缓存
`强缓存：`
通过expire记录过期日期，http1.1中新增cache-control克服请求头限制，且优先级高于expire
cache-control:no-cache/private/max-age=3600...（具体可到MDN查看）
(https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/Cache-Control)

`协商缓存`
ETag+if-none-match和last-modified+if-modified-since,前者优先级大于后者
服务器返回页面A，并在给A加上一个ETag。 客户端展现该页面，并将页面连同ETag一起缓存。 客户再次请求页面A，并将上次请求时服务器返回的ETag一起传递给服务器。 服务器检查该ETag，并判断出该页面自上次客户端请求之后还未被修改，直接返回响应304（未修改——Not Modified）和一个空的响应体。
+++

+++success 浏览器缓存位置
Service Worker
Service Worker 是运行在浏览器背后的独立线程，一般可以用来实现缓存功能。使用 Service Worker 的话，传输协议必须为 HTTPS。Service Worker 的缓存与浏览器其他内建的缓存机制不同，它可以让我们自由缓存哪些文件、如何匹配缓存、如何读取缓存，而缓存是可持续性的。Service Worker 也是 PWA 的核心技术。
Memory Cache
Memory Cache 也就是内存中的缓存，主要包含的是当前页面中已经抓取到的资源，例如页面上已经下载的样式、脚本、图片等。读取内存中的数据很高效，但是缓存持续性很短，会随着进程的释放而释放。一旦我们关闭 Tab 页面，内存中的缓存也就被释放了。
Disk Cache
Disk Cache 也就是存储在硬盘中的缓存，读取速度慢点，但是什么都能存储到磁盘中，比之 Memory Cache 胜在容量和存储时效性上。在所有浏览器缓存中，Disk Cache 覆盖面基本上是最大的。它会根据 HTTPHeader 中的字段判断哪些资源需要缓存，哪些资源可以不请求直接使用，哪些资源已经过期需要重新请求。并且即使在跨站点的情况下，相同地址的资源一旦被硬盘缓存下来，就不会再次去请求数据。绝大部分的缓存都来自 Disk Cache。
Push Cache
Push Cache（推送缓存）是 HTTP/2 中的内容，当以上三种缓存都没有命中时，它才会被时候用。它只在会话（Session）中存在，一旦会话结束就被释放，并且缓存时间也很短暂（大约 5 分钟）。

(https://juejin.cn/post/6844903747357769742?utm_source=gold_browser_extension)

优先级 Service Worker > memory cache > disk cache > Push Cache

最佳实践：资源尽可能命中强缓存，且在资源文件更新时保证用户使用到最新的资源文件
强缓存只会命中相同命名的资源文件。
在资源文件上加 hash 标识（webpack 可在打包时在文件名上带上）。
通过更新资源文件名来强制更新命中强缓存的资源。
+++

+++success no-cache和no-store 的区别。
前者可以在客户端存储资源，但每次都必须去服务端做新鲜度校验，决定从服务端获取新资源（200）还是作缓存（304）处理
后者为不做缓存处理
+++

+++success HTTP状态码304是多好还是少好
服务器为了提高网站访问速度，对之前访问的部分页面指定缓存机制，当客户端在此对这些页面进行请求，服务器会根据缓存内容判断页面与之前是否相同，若相同便直接返回304，此时客户端调用缓存内容，不必进行二次下载。

状态码304不应该认为是一种错误，而是对客户端有缓存情况下服务端的一种响应。

搜索引擎蜘蛛会更加青睐内容源更新频繁的网站。通过特定时间内对网站抓取返回的状态码来调节对该网站的抓取频次。若网站在一定时间内一直处于304的状态，那么蜘蛛可能会降低对网站的抓取次数。相反，若网站变化的频率非常之快，每次抓取都能获取新内容，那么日积月累，的回访率也会提高。

产生较多304状态码的原因：

- 页面更新周期长或不更新
- 纯静态页面或强制生成静态html

304状态码出现过多会造成以下问题：

- 网站快照停止；
- 收录减少；
- 权重下降。

+++
